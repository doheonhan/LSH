{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e598772",
   "metadata": {},
   "source": [
    "# Here, we do training/validation (70%) with all oversampled datasets (5-fold cross-validation) and Testing (30%). The best-performing for each method will be done later (not here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Common Functions ####################################\n",
    "def get_results(y, predicted, pred_prob):\n",
    "    if np.isnan(predicted).any():\n",
    "        acc = 0\n",
    "        pre = 0\n",
    "        rec = 0\n",
    "        spe = 0\n",
    "        f1 = 0\n",
    "        gmean = 0\n",
    "        bacc = 0\n",
    "        rauc = 0\n",
    "    else:\n",
    "        TN = metrics.confusion_matrix(y, predicted)[0,0]\n",
    "        try:\n",
    "            FP = metrics.confusion_matrix(y, predicted)[0,1]\n",
    "        except:\n",
    "            FP = 0\n",
    "        try:\n",
    "            FN = metrics.confusion_matrix(y, predicted)[1,0]\n",
    "        except:\n",
    "            FN = 0\n",
    "        try:\n",
    "            TP = metrics.confusion_matrix(y, predicted)[1,1]\n",
    "        except:\n",
    "            TP = 0\n",
    "            #         acc = np.round((TP+TN)/(TP+TN+FP+FN),4)\n",
    "#         if TP+FP == 0:\n",
    "#             pre = 0\n",
    "#         else:\n",
    "#             pre = np.round(TP/(TP+FP),4)\n",
    "#         rec = np.round(TP/(TP+FN),4)\n",
    "#         spe = np.round(TN/(FP+TN),4)\n",
    "#         f1 = np.round(TP/(TP + 0.5*(FP+FN)),4)\n",
    "#         gmean = np.round(((TP/(TP+FN)) * (TN/(TN+FP)))**0.5,4)\n",
    "#         bacc = np.round(0.5*(TP/(TP+FN) + TN/(TN+FP)),4)*2\n",
    "        acc = np.round(accuracy_score(y, predicted),4)\n",
    "        pre = np.round(precision_score(y, predicted),4)\n",
    "        rec = np.round(recall_score(y, predicted),4)\n",
    "        spe = np.round(TN/(FP+TN),4)\n",
    "        f1 = np.round(f1_score(y, predicted),4)\n",
    "        gmean = np.round(geometric_mean_score(y, predicted),4)\n",
    "        bacc = np.round(balanced_accuracy_score(y, predicted),4)\n",
    "        try:\n",
    "            rauc = np.round(roc_auc_score(y, pred_prob),4)\n",
    "        except:\n",
    "            rauc = 0\n",
    "    \n",
    "    return acc, pre, rec, spe, f1, gmean, bacc, rauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9857681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)   # 5-fold-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ccba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [18, 41, 14, 43, 53, 28, 20, 63, 69, 56, 19, 25, 6, 24, 80, 32, 22, 15, 27, 33, 58,\n",
    "              46, 29, 64, 62, 17, 47, 13, 44, 9, 49, 55, 3, 35, 67, 54, 12, 7, 39, 36, 4, 79, 59, 52, 5, 57,\n",
    "              21, 50, 45, 42, 11, 1, 51, 38, 34, 16, 10, 2, 26, 91]\n",
    "print(len(final_list), final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d84124",
   "metadata": {},
   "source": [
    "## Validation (70 => train:val = 56:14, 5CV) and Test(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Strategy = [0.2, 0.4, 0.6, 0.8, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = []\n",
    "\n",
    "# Logistic Regression  # 7\n",
    "param_lr = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "# print(len(list(param_lr.items()))) # 1\n",
    "for i in range(len(list(param_lr.items())[0][1])):\n",
    "    Model.append(LogisticRegression(random_state=100, max_iter=100000,    #class_weight='balanced', \n",
    "                                    C=param_lr[list(param_lr.keys())[0]][i]))\n",
    "\n",
    "# Decision Tree  # 4*3*3=36\n",
    "param_dt = {'max_depth':[10,20,30,40],\n",
    "            'min_samples_split':[2,4,6], \n",
    "            'min_samples_leaf':[1,2,3]}\n",
    "# print(len(list(param_dt.items()))) # 3\n",
    "for i in range(len(list(param_dt.items())[0][1])):\n",
    "    for j in range(len(list(param_dt.items())[1][1])):\n",
    "        for k in range(len(list(param_dt.items())[2][1])):\n",
    "            Model.append(DecisionTreeClassifier(random_state=100,    #class_weight='balanced', \n",
    "                                                max_depth=param_dt[list(param_dt.keys())[0]][i], \n",
    "                                                min_samples_split=param_dt[list(param_dt.keys())[1]][j], \n",
    "                                                min_samples_leaf=param_dt[list(param_dt.keys())[2]][k]))\n",
    "\n",
    "# SVM  # 3*2*4=24\n",
    "param_svm = {'C':[0.1, 1, 10],\n",
    "             'kernel':['rbf', 'sigmoid'],\n",
    "             'gamma':['scale', 'auto', 0.1, 1]}\n",
    "# print(len(list(param_svm.items()))) # 2\n",
    "for i in range(len(list(param_svm.items())[0][1])):\n",
    "    for j in range(len(list(param_svm.items())[1][1])):\n",
    "        for k in range(len(list(param_svm.items())[2][1])):\n",
    "            Model.append(svm.SVC(random_state=100, probability=True,     #class_weight='balanced', \n",
    "                                 C=param_svm[list(param_svm.keys())[0]][i],\n",
    "                                 kernel=param_svm[list(param_svm.keys())[1]][j],\n",
    "                                 gamma=param_svm[list(param_svm.keys())[2]][k]))\n",
    "        \n",
    "# KNN  # 4*2*3=24\n",
    "param_knn = {'n_neighbors':[3, 5, 7, 9],\n",
    "             'p':[1, 2],\n",
    "             'metric':['euclidean','manhattan', 'minkowski']}\n",
    "# print(len(list(param_knn.items()))) # 3\n",
    "for i in range(len(list(param_knn.items())[0][1])):\n",
    "    for j in range(len(list(param_knn.items())[1][1])):\n",
    "        for k in range(len(list(param_knn.items())[2][1])):\n",
    "            Model.append(neighbors.KNeighborsClassifier(n_neighbors=param_knn[list(param_knn.keys())[0]][i],\n",
    "                                                        p=param_knn[list(param_knn.keys())[1]][j],\n",
    "                                                        metric=param_knn[list(param_knn.keys())[2]][k]))\n",
    "            \n",
    "# LGBM  # 3*2*2*4=48\n",
    "param_lg = {'boosting_type' : ['gbdt', 'dart', 'goss'],\n",
    "            'max_depth' : [10,20], \n",
    "            'learning_rate' : [0.01,0.05],\n",
    "            'n_estimators' : list(range(0,201,50))[1:]}\n",
    "# print(len(list(param_lg.items()))) # 3\n",
    "for i in range(len(list(param_lg.items())[0][1])):\n",
    "    for j in range(len(list(param_lg.items())[1][1])):\n",
    "        for k in range(len(list(param_lg.items())[2][1])):\n",
    "            for l in range(len(list(param_lg.items())[3][1])):\n",
    "                Model.append(LGBMClassifier(random_state=100, objective='binary',     #is_unbalance=True,\n",
    "                                            boosting_type=param_lg[list(param_lg.keys())[0]][i],\n",
    "                                            max_depth=param_lg[list(param_lg.keys())[1]][j],\n",
    "                                            learning_rate=param_lg[list(param_lg.keys())[2]][k],\n",
    "                                            n_estimators=param_lg[list(param_lg.keys())[3]][l]))\n",
    "\n",
    "print(len(Model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelName = []\n",
    "\n",
    "# LR\n",
    "tot_num = 1\n",
    "for i in range(len(list(param_lr.keys()))):\n",
    "    tot_num *= len(param_lr[list(param_lr.keys())[i]])\n",
    "for i in range(tot_num):\n",
    "    ModelName.append('LR'+str(i+1))\n",
    "    \n",
    "    \n",
    "# DT\n",
    "tot_num = 1\n",
    "for i in range(len(list(param_dt.keys()))):\n",
    "    tot_num *= len(param_dt[list(param_dt.keys())[i]])\n",
    "for i in range(tot_num):\n",
    "    ModelName.append('DT'+str(i+1))    \n",
    "    \n",
    "# SVM\n",
    "tot_num = 1\n",
    "for i in range(len(list(param_svm.keys()))):\n",
    "    tot_num *= len(param_svm[list(param_svm.keys())[i]])\n",
    "for i in range(tot_num):\n",
    "    ModelName.append('SVM'+str(i+1)) \n",
    "    \n",
    "# KNN\n",
    "tot_num = 1\n",
    "for i in range(len(list(param_knn.keys()))):\n",
    "    tot_num *= len(param_knn[list(param_knn.keys())[i]])\n",
    "for i in range(tot_num):\n",
    "    ModelName.append('KNN'+str(i+1)) \n",
    "    \n",
    "# LGBM\n",
    "tot_num = 1\n",
    "for i in range(len(list(param_lg.keys()))):\n",
    "    tot_num *= len(param_lg[list(param_lg.keys())[i]])\n",
    "for i in range(tot_num):\n",
    "    ModelName.append('LG'+str(i+1))\n",
    "    \n",
    "print(len(ModelName))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd60fd",
   "metadata": {},
   "source": [
    "# 1. ORIGINAL (No oversampling) / SMOTE (or BSM/ADA) / LLM (GPT/DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77603c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in final_list: \n",
    "    start = time.time()\n",
    "    df = pd.read_csv('data_newest/ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]        # For validation\n",
    "    y = df_val.iloc[:, -1]         # For validation\n",
    "    X_test = df_test.iloc[:, :-1]  # For test\n",
    "    y_test = df_test.iloc[:, -1]   # For test\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.astype(float)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = y_test.astype(float)\n",
    "    \n",
    "    res_df = pd.DataFrame({'Dataset':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, \n",
    "                       index = ['Acc_tr','Pre_tr','Rec_tr','Spe_tr','F1_tr','Gmean_tr','B_Acc_tr','R-AUC_tr',\n",
    "                                'Acc_val','Pre_val','Rec_val','Spe_val','F1_val','Gmean_val','B_Acc_val','R-AUC_val',\n",
    "                                'Acc_t','Pre_t','Rec_t','Spe_t','F1_t','Gmean_t','B_Acc_t','R-AUC_t'])\n",
    "    res_df.iloc[:,0] = [i for b in range(24)]\n",
    "    \n",
    "    ##################### For Loop for Every Loss Functions ####################### \n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]\n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    print(\"==========\", \"Original\", \"==========\")\n",
    "    for k in range(len(Model)):\n",
    "        train_acc = []\n",
    "        train_pre = []\n",
    "        train_rec = []\n",
    "        train_spe = []\n",
    "        train_f1 = []\n",
    "        train_gmean = []\n",
    "        train_bacc = []\n",
    "        train_rauc = []\n",
    "        \n",
    "        list_acc = []\n",
    "        list_pre = []\n",
    "        list_rec = []\n",
    "        list_spe = []\n",
    "        list_f1 = []\n",
    "        list_gmean = []\n",
    "        list_bacc = []\n",
    "        list_rauc = []\n",
    "        \n",
    "        # 5-fold-CV\n",
    "        n_iter=0\n",
    "        for train_index, val_index in skf.split(X, y):\n",
    "            model = Model[k]\n",
    "            n_iter += 1\n",
    "            X_train = X.iloc[train_index]\n",
    "            y_train= y.iloc[train_index]\n",
    "            if k == 0 and n_iter == 1:\n",
    "                print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "            X_val = X.iloc[val_index]\n",
    "            y_val= y.iloc[val_index]\n",
    "            if k == 0 and n_iter == 1:\n",
    "                print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "            # Array\n",
    "            X_train = np.array(X_train)\n",
    "            X_train = X_train.astype(float)\n",
    "            y_train = np.array(y_train)\n",
    "            y_train = y_train.astype(float)\n",
    "            X_val = np.array(X_val)\n",
    "            X_val = X_val.astype(float)\n",
    "            y_val = np.array(y_val)\n",
    "            y_val = y_val.astype(float)\n",
    "            # Learning\n",
    "            model.fit(X_train, y_train)\n",
    "            train_result = model.predict(X_train)\n",
    "            train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "            acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "            train_acc.append(acc)\n",
    "            train_pre.append(pre)\n",
    "            train_rec.append(rec)\n",
    "            train_spe.append(spe)\n",
    "            train_f1.append(f1)\n",
    "            train_gmean.append(gmean)\n",
    "            train_bacc.append(bacc)\n",
    "            train_rauc.append(rauc) \n",
    "            # Results \n",
    "            result = model.predict(X_val)\n",
    "            result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "            acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "            list_acc.append(acc)\n",
    "            list_pre.append(pre)\n",
    "            list_rec.append(rec)\n",
    "            list_spe.append(spe)\n",
    "            list_f1.append(f1)\n",
    "            list_gmean.append(gmean)\n",
    "            list_bacc.append(bacc)\n",
    "            list_rauc.append(rauc) \n",
    "        \n",
    "        # Test\n",
    "        if k == 0:\n",
    "            print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))  \n",
    "        model = Model[k]\n",
    "        model.fit(np.array(X).astype(float), np.array(y).astype(float))\n",
    "        result = model.predict(X_test)\n",
    "        result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "        acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "        \n",
    "        res_df['{}'.format(ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                             np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                             np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                             np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                             acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        for k in range(len(Model)):   \n",
    "            train_acc = []\n",
    "            train_pre = []\n",
    "            train_rec = []\n",
    "            train_spe = []\n",
    "            train_f1 = []\n",
    "            train_gmean = []\n",
    "            train_bacc = []\n",
    "            train_rauc = []   \n",
    "            list_acc = []\n",
    "            list_pre = []\n",
    "            list_rec = []\n",
    "            list_spe = []\n",
    "            list_f1 = []\n",
    "            list_gmean = []\n",
    "            list_bacc = []\n",
    "            list_rauc = []\n",
    "                \n",
    "            if min_strategy > Strategy[j]:\n",
    "                train_acc.append(0)\n",
    "                train_pre.append(0)\n",
    "                train_rec.append(0)\n",
    "                train_spe.append(0)\n",
    "                train_f1.append(0)\n",
    "                train_gmean.append(0)\n",
    "                train_bacc.append(0)\n",
    "                train_rauc.append(0)\n",
    "                list_acc.append(0)\n",
    "                list_pre.append(0)\n",
    "                list_rec.append(0)\n",
    "                list_spe.append(0)\n",
    "                list_f1.append(0)\n",
    "                list_gmean.append(0)\n",
    "                list_bacc.append(0)\n",
    "                list_rauc.append(0)\n",
    "                acc_t = 0\n",
    "                pre_t = 0\n",
    "                rec_t = 0\n",
    "                spe_t = 0\n",
    "                f1_t = 0\n",
    "                gmean_t = 0\n",
    "                bacc_t = 0\n",
    "                rauc_t = 0\n",
    "            \n",
    "            else:               \n",
    "                # 5-fold-CV\n",
    "                n_iter=0\n",
    "                for train_index, val_index in skf.split(X, y):\n",
    "                    model = Model[k]\n",
    "                    n_iter += 1\n",
    "                    X_train = X.iloc[train_index]\n",
    "                    y_train= y.iloc[train_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))     \n",
    "                    # Loading Resmapled Data\n",
    "                    over_df = pd.read_csv('SMOTE_over/'\n",
    "                                          +'ds'+str(i)+'_S_'+str(Strategy[j])+'_'+str(n_iter)+'th.csv')\n",
    "                    over_df = over_df.replace('False', False)\n",
    "                    over_df = over_df.replace('FALSE', False)\n",
    "                    over_df = over_df.fillna(df.mean())\n",
    "                    X_train = over_df.iloc[:, :-1]\n",
    "                    y_train = over_df.iloc[:, -1]     \n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN_over(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))    \n",
    "                    X_val = X.iloc[val_index]\n",
    "                    y_val= y.iloc[val_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                    # Array\n",
    "                    X_train = np.array(X_train)\n",
    "                    X_train = X_train.astype(float)\n",
    "                    y_train = np.array(y_train)\n",
    "                    y_train = y_train.astype(float)\n",
    "                    X_val = np.array(X_val)\n",
    "                    X_val = X_val.astype(float)\n",
    "                    y_val = np.array(y_val)\n",
    "                    y_val = y_val.astype(float)\n",
    "                    # Learning\n",
    "                    model.fit(X_train, y_train)\n",
    "                    train_result = model.predict(X_train)\n",
    "                    train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                    train_acc.append(acc)\n",
    "                    train_pre.append(pre)\n",
    "                    train_rec.append(rec)\n",
    "                    train_spe.append(spe)\n",
    "                    train_f1.append(f1)\n",
    "                    train_gmean.append(gmean)\n",
    "                    train_bacc.append(bacc)\n",
    "                    train_rauc.append(rauc) \n",
    "                    # Results \n",
    "                    result = model.predict(X_val)\n",
    "                    result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                    list_acc.append(acc)\n",
    "                    list_pre.append(pre)\n",
    "                    list_rec.append(rec)\n",
    "                    list_spe.append(spe)\n",
    "                    list_f1.append(f1)\n",
    "                    list_gmean.append(gmean)\n",
    "                    list_bacc.append(bacc)\n",
    "                    list_rauc.append(rauc)\n",
    "                            \n",
    "                # Test\n",
    "                model = Model[k]\n",
    "                # Loading Resmapled Data\n",
    "                over_df = pd.read_csv(r'SMOTE_over/'\n",
    "                                      +'ds'+str(i)+'_S_'+str(Strategy[j])+'_'+str('full')+'.csv')\n",
    "                over_df = over_df.replace('False', False)\n",
    "                over_df = over_df.replace('FALSE', False)\n",
    "                over_df = over_df.fillna(df.mean())\n",
    "                X_over = over_df.iloc[:, :-1]\n",
    "                y_over = over_df.iloc[:, -1]\n",
    "                if k == 0:\n",
    "                    print(\"TRAIN_over(0/1/total):\", list(y_over).count(0), list(y_over).count(1), len(y_over))\n",
    "                    print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))\n",
    "                model.fit(np.array(X_over).astype(float), np.array(y_over).astype(float))\n",
    "                result = model.predict(X_test)\n",
    "                result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "                acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "                                                                                        \n",
    "            res_df['S_{}_{}'.format(Strategy[j],ModelName[k])] = [np.mean(train_acc), np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                                                  np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                                                  np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                                                  np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                                                  acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "            \n",
    "    for h in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_{}\".format(Strategy[h]), \"==========\")         \n",
    "        for k in range(len(Model)):     \n",
    "            train_acc = []\n",
    "            train_pre = []\n",
    "            train_rec = []\n",
    "            train_spe = []\n",
    "            train_f1 = []\n",
    "            train_gmean = []\n",
    "            train_bacc = []\n",
    "            train_rauc = []      \n",
    "            list_acc = []\n",
    "            list_pre = []\n",
    "            list_rec = []\n",
    "            list_spe = []\n",
    "            list_f1 = []\n",
    "            list_gmean = []\n",
    "            list_bacc = []\n",
    "            list_rauc = []\n",
    "            \n",
    "            if min_strategy > Strategy[h]:\n",
    "                train_acc.append(0)\n",
    "                train_pre.append(0)\n",
    "                train_rec.append(0)\n",
    "                train_spe.append(0)\n",
    "                train_f1.append(0)\n",
    "                train_gmean.append(0)\n",
    "                train_bacc.append(0)\n",
    "                train_rauc.append(0)\n",
    "                list_acc.append(0)\n",
    "                list_pre.append(0)\n",
    "                list_rec.append(0)\n",
    "                list_spe.append(0)\n",
    "                list_f1.append(0)\n",
    "                list_gmean.append(0)\n",
    "                list_bacc.append(0)\n",
    "                list_rauc.append(0)\n",
    "                acc_t = 0\n",
    "                pre_t = 0\n",
    "                rec_t = 0\n",
    "                spe_t = 0\n",
    "                f1_t = 0\n",
    "                gmean_t = 0\n",
    "                bacc_t = 0\n",
    "                rauc_t = 0\n",
    "            \n",
    "            else:\n",
    "                # 5-fold-CV\n",
    "                n_iter=0\n",
    "                for train_index, val_index in skf.split(X, y):\n",
    "                    model = Model[k]\n",
    "                    n_iter += 1\n",
    "                    X_train = X.iloc[train_index]\n",
    "                    y_train= y.iloc[train_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                    # Loading Resmapled Data\n",
    "                    over_df = pd.read_csv('LLM_over/'\n",
    "                                          +'ds'+str(i)+'_L_'+str(Strategy[h])+'_'+str(n_iter)+'th.csv')\n",
    "                    over_df = over_df.replace('False', False)  # sometimes False happen\n",
    "                    over_df = over_df.replace('FALSE', False)\n",
    "                    over_df = over_df.fillna(df.mean())   # sometime NAN happen\n",
    "                    X_train = over_df.iloc[:, :-1]\n",
    "                    y_train = over_df.iloc[:, -1]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN_over(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                    X_val = X.iloc[val_index]\n",
    "                    y_val = y.iloc[val_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                    # Array\n",
    "                    X_train = np.array(X_train)\n",
    "                    X_train = X_train.astype(float)\n",
    "                    y_train = np.array(y_train)\n",
    "                    y_train = y_train.astype(float)\n",
    "                    X_val = np.array(X_val)\n",
    "                    X_val = X_val.astype(float)\n",
    "                    y_val = np.array(y_val)\n",
    "                    y_val = y_val.astype(float)\n",
    "                    # Learning\n",
    "                    model.fit(X_train, y_train)\n",
    "                    train_result = model.predict(X_train)\n",
    "                    train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                    train_acc.append(acc)\n",
    "                    train_pre.append(pre)\n",
    "                    train_rec.append(rec)\n",
    "                    train_spe.append(spe)\n",
    "                    train_f1.append(f1)\n",
    "                    train_gmean.append(gmean)\n",
    "                    train_bacc.append(bacc)\n",
    "                    train_rauc.append(rauc) \n",
    "                    # Results \n",
    "                    result = model.predict(X_val)\n",
    "                    result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                    list_acc.append(acc)\n",
    "                    list_pre.append(pre)\n",
    "                    list_rec.append(rec)\n",
    "                    list_spe.append(spe)\n",
    "                    list_f1.append(f1)\n",
    "                    list_gmean.append(gmean)\n",
    "                    list_bacc.append(bacc)\n",
    "                    list_rauc.append(rauc)\n",
    "                            \n",
    "                # Test     \n",
    "                model = Model[k]\n",
    "                # Loading Resmapled Data\n",
    "                over_df = pd.read_csv(r'LLM_over/'\n",
    "                                      +'ds'+str(i)+'_L_'+str(Strategy[h])+'_'+str('comb')+'.csv')\n",
    "                over_df = over_df.replace('False', False)  # sometimes False happen\n",
    "                over_df = over_df.replace('FALSE', False)\n",
    "                over_df = over_df.fillna(df.mean())   # sometime NAN happen\n",
    "                X_over = over_df.iloc[:, :-1]\n",
    "                y_over = over_df.iloc[:, -1]\n",
    "                if k == 0:\n",
    "                    print(\"TRAIN_over(0/1/total):\", list(y_over).count(0), list(y_over).count(1), len(y_over))\n",
    "                    print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))\n",
    "                model.fit(np.array(X_over).astype(float), np.array(y_over).astype(float))\n",
    "                result = model.predict(X_test)\n",
    "                result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "                acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "            res_df['L_{}_{}'.format(Strategy[h],ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                                                  np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                                                  np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                                                  np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                                                  acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    res_df.to_csv(\"validation_test.csv\", mode = 'a', float_format='%.4g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0c16a",
   "metadata": {},
   "source": [
    "# 2. LSH (GPT+SMOTE or DEV+SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2beaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in final_list: \n",
    "    df = pd.read_csv('data_newest/ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]        # For validation\n",
    "    y = df_val.iloc[:, -1]         # For validation \n",
    "    X_test = df_test.iloc[:, :-1]  # For test\n",
    "    y_test = df_test.iloc[:, -1]   # For test\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.astype(float)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = y_test.astype(float)\n",
    "    \n",
    "    res_df = pd.DataFrame({'Dataset':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, \n",
    "                       index = ['Acc_tr','Pre_tr','Rec_tr','Spe_tr','F1_tr','Gmean_tr','B_Acc_tr','R-AUC_tr',\n",
    "                                'Acc_val','Pre_val','Rec_val','Spe_val','F1_val','Gmean_val','B_Acc_val','R-AUC_val',\n",
    "                                'Acc_t','Pre_t','Rec_t','Spe_t','F1_t','Gmean_t','B_Acc_t','R-AUC_t'])\n",
    "    res_df.iloc[:,0] = [i for b in range(24)]\n",
    "    \n",
    "    ##################### For Loop for Every Loss Functions ####################### \n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]\n",
    "    adj_strategy = Strategy[ind+1]  # original min_strategy-> LLM oversmaple, so SMOTE is used from the next \n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "        adj_strategy = Strategy[2]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        for k in range(len(Model)):  \n",
    "            train_acc = []\n",
    "            train_pre = []\n",
    "            train_rec = []\n",
    "            train_spe = []\n",
    "            train_f1 = []\n",
    "            train_gmean = []\n",
    "            train_bacc = []\n",
    "            train_rauc = []    \n",
    "            list_acc = []\n",
    "            list_pre = []\n",
    "            list_rec = []\n",
    "            list_spe = []\n",
    "            list_f1 = []\n",
    "            list_gmean = []\n",
    "            list_bacc = []\n",
    "            list_rauc = []\n",
    "                \n",
    "            if adj_strategy > Strategy[j]:\n",
    "                train_acc.append(0)\n",
    "                train_pre.append(0)\n",
    "                train_rec.append(0)\n",
    "                train_spe.append(0)\n",
    "                train_f1.append(0)\n",
    "                train_gmean.append(0)\n",
    "                train_bacc.append(0)\n",
    "                train_rauc.append(0)\n",
    "                list_acc.append(0)\n",
    "                list_pre.append(0)\n",
    "                list_rec.append(0)\n",
    "                list_spe.append(0)\n",
    "                list_f1.append(0)\n",
    "                list_gmean.append(0)\n",
    "                list_bacc.append(0)\n",
    "                list_rauc.append(0)\n",
    "                acc_t = 0\n",
    "                pre_t = 0\n",
    "                rec_t = 0\n",
    "                spe_t = 0\n",
    "                f1_t = 0\n",
    "                gmean_t = 0\n",
    "                bacc_t = 0\n",
    "                rauc_t = 0\n",
    "            \n",
    "            else:\n",
    "                # 5-fold-CV\n",
    "                n_iter=0\n",
    "                for train_index, val_index in skf.split(X, y):\n",
    "                    model = Model[k]\n",
    "                    n_iter += 1\n",
    "                    X_train = X.iloc[train_index]\n",
    "                    y_train= y.iloc[train_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))     \n",
    "                    # Loading Resmapled Data\n",
    "                    over_df = pd.read_csv('LLM_SMOTE/'\n",
    "                                          +'ds'+str(i)+'_LS_'+str(Strategy[j])+'_'+str(n_iter)+'th.csv')\n",
    "                    over_df = over_df.replace('False', False)\n",
    "                    over_df = over_df.fillna(df.mean())\n",
    "                    X_train = over_df.iloc[:, :-1]\n",
    "                    y_train = over_df.iloc[:, -1]     \n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN_over(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))    \n",
    "                    X_val = X.iloc[val_index]\n",
    "                    y_val= y.iloc[val_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                    # Array\n",
    "                    X_train = np.array(X_train)\n",
    "                    X_train = X_train.astype(float)\n",
    "                    y_train = np.array(y_train)\n",
    "                    y_train = y_train.astype(float)\n",
    "                    X_val = np.array(X_val)\n",
    "                    X_val = X_val.astype(float)\n",
    "                    y_val = np.array(y_val)\n",
    "                    y_val = y_val.astype(float)\n",
    "                    # Learning\n",
    "                    model.fit(X_train, y_train)\n",
    "                    train_result = model.predict(X_train)\n",
    "                    train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                    train_acc.append(acc)\n",
    "                    train_pre.append(pre)\n",
    "                    train_rec.append(rec)\n",
    "                    train_spe.append(spe)\n",
    "                    train_f1.append(f1)\n",
    "                    train_gmean.append(gmean)\n",
    "                    train_bacc.append(bacc)\n",
    "                    train_rauc.append(rauc)\n",
    "                    # Results \n",
    "                    result = model.predict(X_val)\n",
    "                    result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                    list_acc.append(acc)\n",
    "                    list_pre.append(pre)\n",
    "                    list_rec.append(rec)\n",
    "                    list_spe.append(spe)\n",
    "                    list_f1.append(f1)\n",
    "                    list_gmean.append(gmean)\n",
    "                    list_bacc.append(bacc)\n",
    "                    list_rauc.append(rauc)\n",
    "                            \n",
    "                # Test\n",
    "                model = Model[k]\n",
    "                # Loading Resmapled Data\n",
    "                over_df = pd.read_csv(r'LLM_SMOTE/'\n",
    "                                      +'ds'+str(i)+'_LS_'+str(Strategy[j])+'_'+str('comb')+'.csv')\n",
    "                over_df = over_df.replace('False', False)\n",
    "                over_df = over_df.fillna(df.mean())\n",
    "                X_over = over_df.iloc[:, :-1]\n",
    "                y_over = over_df.iloc[:, -1]     \n",
    "                if k == 0:\n",
    "                    print(\"TRAIN_over(0/1/total):\", list(y_over).count(0), list(y_over).count(1), len(y_over)) \n",
    "                    print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test)) \n",
    "                model.fit(np.array(X_over).astype(float), np.array(y_over).astype(float))\n",
    "                result = model.predict(X_test)\n",
    "                result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "                acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "\n",
    "\n",
    "            res_df['LS_{}_{}'.format(Strategy[j],ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                                                   np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                                                   np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                                                   np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                                                   acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "            \n",
    "    res_df.to_csv(\"validation_test_LS.csv\", mode = 'a', float_format='%.4g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343cd0c9",
   "metadata": {},
   "source": [
    "# 3. Very Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0391513",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_imb_list = ['ds8_new_05', 'ds8_new_01', 'ds8_new_00',\n",
    "'ds58_new_05', 'ds58_new_01', 'ds58_new_00',\n",
    "'ds14_new_05', 'ds14_new_01', 'ds14_new_00',\n",
    "'ds44_new_05', 'ds44_new_01', 'ds44_new_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1a1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here, we get validation scores, not test scores.\n",
    "for i in very_imb_list:\n",
    "    df = pd.read_csv('data_newest/'+ str(i) +'.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    try:\n",
    "        minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    except:\n",
    "        minor = \"NONE\"    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    try:\n",
    "        print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "    except:\n",
    "        print('<Imabalance ratio>\\n',\"1: 0.00\")\n",
    "        \n",
    "    # For validation & test (adding more data points removed from original dataset)\n",
    "    val_add = pd.read_csv('data_newest/'+str(i)+'_val.csv')\n",
    "    val_add.iloc[:,-1] = val_add.iloc[:,-1].replace(2, 1)\n",
    "    val_add.rename(columns={val_add.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    test_add = pd.read_csv('data_newest/'+str(i)+'_test.csv')\n",
    "    test_add.iloc[:,-1] = test_add.iloc[:,-1].replace(2, 1)\n",
    "    test_add.rename(columns={test_add.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]        # For validation\n",
    "    y = df_val.iloc[:, -1]         # For validation    \n",
    "    df_test = pd.concat([test_add, df_test], axis=0)\n",
    "    X_test = df_test.iloc[:, :-1]  # For test\n",
    "    y_test = df_test.iloc[:, -1]   # For test\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.astype(float)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = y_test.astype(float)\n",
    "    \n",
    "    res_df = pd.DataFrame({'Dataset':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, \n",
    "                       index = ['Acc_tr','Pre_tr','Rec_tr','Spe_tr','F1_tr','Gmean_tr','B_Acc_tr','R-AUC_tr',\n",
    "                                'Acc_val','Pre_val','Rec_val','Spe_val','F1_val','Gmean_val','B_Acc_val','R-AUC_val',\n",
    "                                'Acc_t','Pre_t','Rec_t','Spe_t','F1_t','Gmean_t','B_Acc_t','R-AUC_t'])\n",
    "    res_df.iloc[:,0] = [i for b in range(24)]\n",
    "    \n",
    "    ##################### For Loop for Every Loss Functions ####################### \n",
    "    try:\n",
    "        ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    except:\n",
    "        ind = 0\n",
    "    min_strategy = Strategy[ind]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    print(\"==========\", \"Original\", \"==========\")\n",
    "    for k in range(len(Model)):  \n",
    "        train_acc = []\n",
    "        train_pre = []\n",
    "        train_rec = []\n",
    "        train_spe = []\n",
    "        train_f1 = []\n",
    "        train_gmean = []\n",
    "        train_bacc = []\n",
    "        train_rauc = []    \n",
    "        list_acc = []\n",
    "        list_pre = []\n",
    "        list_rec = []\n",
    "        list_spe = []\n",
    "        list_f1 = []\n",
    "        list_gmean = []\n",
    "        list_bacc = []\n",
    "        list_rauc = []\n",
    "        \n",
    "        if i in very_imb_list[2:]:  # no label '1' in training set, no training available\n",
    "            train_acc.append(0)\n",
    "            train_pre.append(0)\n",
    "            train_rec.append(0)\n",
    "            train_spe.append(0)\n",
    "            train_f1.append(0)\n",
    "            train_gmean.append(0)\n",
    "            train_bacc.append(0)\n",
    "            train_rauc.append(0)\n",
    "            list_acc.append(0)\n",
    "            list_pre.append(0)\n",
    "            list_rec.append(0)\n",
    "            list_spe.append(0)\n",
    "            list_f1.append(0)\n",
    "            list_gmean.append(0)\n",
    "            list_bacc.append(0)\n",
    "            list_rauc.append(0)\n",
    "            acc_t = 0\n",
    "            pre_t = 0\n",
    "            rec_t = 0\n",
    "            spe_t = 0\n",
    "            f1_t = 0\n",
    "            gmean_t = 0\n",
    "            bacc_t = 0\n",
    "            rauc_t = 0\n",
    "        \n",
    "        else:\n",
    "            # 5-fold-CV\n",
    "            n_iter=0\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                model = Model[k]\n",
    "                n_iter += 1\n",
    "                X_train = X.iloc[train_index]\n",
    "                y_train= y.iloc[train_index]\n",
    "                if k == 0 and n_iter == 1:\n",
    "                    print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                X_val = X.iloc[val_index]\n",
    "                X_val = pd.concat([val_add.iloc[:,:-1], X_val], axis=0)\n",
    "                y_val= y.iloc[val_index]\n",
    "                y_val = pd.concat([val_add.iloc[:,-1], y_val], axis=0)\n",
    "                if k == 0 and n_iter == 1:\n",
    "                    print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                # Array\n",
    "                X_train = np.array(X_train)\n",
    "                X_train = X_train.astype(float)\n",
    "                y_train = np.array(y_train)\n",
    "                y_train = y_train.astype(float)\n",
    "                X_val = np.array(X_val)\n",
    "                X_val = X_val.astype(float)\n",
    "                y_val = np.array(y_val)\n",
    "                y_val = y_val.astype(float)\n",
    "                # Learning\n",
    "                model.fit(X_train, y_train)  \n",
    "                train_result = model.predict(X_train)\n",
    "                train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                train_acc.append(acc)\n",
    "                train_pre.append(pre)\n",
    "                train_rec.append(rec)\n",
    "                train_spe.append(spe)\n",
    "                train_f1.append(f1)\n",
    "                train_gmean.append(gmean)\n",
    "                train_bacc.append(bacc)\n",
    "                train_rauc.append(rauc)      \n",
    "                # Results\n",
    "                result = model.predict(X_val)\n",
    "                result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                list_acc.append(acc)\n",
    "                list_pre.append(pre)\n",
    "                list_rec.append(rec)\n",
    "                list_spe.append(spe)\n",
    "                list_f1.append(f1)\n",
    "                list_gmean.append(gmean)\n",
    "                list_bacc.append(bacc)\n",
    "                list_rauc.append(rauc) \n",
    "\n",
    "            # Test\n",
    "            if k == 0:\n",
    "                print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))\n",
    "            model = Model[k]\n",
    "            model.fit(np.array(X).astype(float), np.array(y).astype(float))\n",
    "            result = model.predict(X_test)\n",
    "            result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "            acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "        \n",
    "        res_df['{}'.format(ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                             np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                             np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                             np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                             acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        for k in range(len(Model)):   \n",
    "            train_acc = []\n",
    "            train_pre = []\n",
    "            train_rec = []\n",
    "            train_spe = []\n",
    "            train_f1 = []\n",
    "            train_gmean = []\n",
    "            train_bacc = []\n",
    "            train_rauc = []       \n",
    "            list_acc = []\n",
    "            list_pre = []\n",
    "            list_rec = []\n",
    "            list_spe = []\n",
    "            list_f1 = []\n",
    "            list_gmean = []\n",
    "            list_bacc = []\n",
    "            list_rauc = []\n",
    "                \n",
    "            if min_strategy > Strategy[j] or i in very_imb_list[1:]:  # SMOTE cannot generate\n",
    "                train_acc.append(0)\n",
    "                train_pre.append(0)\n",
    "                train_rec.append(0)\n",
    "                train_spe.append(0)\n",
    "                train_f1.append(0)\n",
    "                train_gmean.append(0)\n",
    "                train_bacc.append(0)\n",
    "                train_rauc.append(0)\n",
    "                list_acc.append(0)\n",
    "                list_pre.append(0)\n",
    "                list_rec.append(0)\n",
    "                list_spe.append(0)\n",
    "                list_f1.append(0)\n",
    "                list_gmean.append(0)\n",
    "                list_bacc.append(0)\n",
    "                list_rauc.append(0)\n",
    "                acc_t = 0\n",
    "                pre_t = 0\n",
    "                rec_t = 0\n",
    "                spe_t = 0\n",
    "                f1_t = 0\n",
    "                gmean_t = 0\n",
    "                bacc_t = 0\n",
    "                rauc_t = 0\n",
    "            \n",
    "            else:\n",
    "                # 5-fold-CV\n",
    "                n_iter=0\n",
    "                for train_index, val_index in skf.split(X, y):\n",
    "                    model = Model[k]\n",
    "                    n_iter += 1\n",
    "                    X_train = X.iloc[train_index]\n",
    "                    y_train= y.iloc[train_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))     \n",
    "                    # Loading Resmapled Data\n",
    "                    over_df = pd.read_csv('SMOTE_over/'\n",
    "                                          +str(i)+'_S_'+str(Strategy[j])+'_'+str(n_iter)+'th.csv')\n",
    "                    over_df = over_df.replace('False', False)\n",
    "                    over_df = over_df.fillna(df.mean())\n",
    "                    X_train = over_df.iloc[:, :-1]\n",
    "                    y_train = over_df.iloc[:, -1]     \n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN_over(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                    X_val = X.iloc[val_index]\n",
    "                    X_val = pd.concat([val_add.iloc[:,:-1], X_val], axis=0)\n",
    "                    y_val= y.iloc[val_index]\n",
    "                    y_val = pd.concat([val_add.iloc[:,-1], y_val], axis=0)\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                    # Array\n",
    "                    X_train = np.array(X_train)\n",
    "                    X_train = X_train.astype(float)\n",
    "                    y_train = np.array(y_train)\n",
    "                    y_train = y_train.astype(float)\n",
    "                    X_val = np.array(X_val)\n",
    "                    X_val = X_val.astype(float)\n",
    "                    y_val = np.array(y_val)\n",
    "                    y_val = y_val.astype(float)\n",
    "                    # Learning\n",
    "                    model.fit(X_train, y_train)  \n",
    "                    train_result = model.predict(X_train)\n",
    "                    train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                    train_acc.append(acc)\n",
    "                    train_pre.append(pre)\n",
    "                    train_rec.append(rec)\n",
    "                    train_spe.append(spe)\n",
    "                    train_f1.append(f1)\n",
    "                    train_gmean.append(gmean)\n",
    "                    train_bacc.append(bacc)\n",
    "                    train_rauc.append(rauc)      \n",
    "                    # Results \n",
    "                    result = model.predict(X_val)\n",
    "                    result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                    list_acc.append(acc)\n",
    "                    list_pre.append(pre)\n",
    "                    list_rec.append(rec)\n",
    "                    list_spe.append(spe)\n",
    "                    list_f1.append(f1)\n",
    "                    list_gmean.append(gmean)\n",
    "                    list_bacc.append(bacc)\n",
    "                    list_rauc.append(rauc)\n",
    "                            \n",
    "                # Test\n",
    "                model = Model[k]\n",
    "                # Loading Resmapled Data\n",
    "                over_df = pd.read_csv('SMOTE_over/'\n",
    "                                      +str(i)+'_S_'+str(Strategy[j])+'_'+str('full')+'.csv')\n",
    "                over_df = over_df.replace('False', False)\n",
    "                over_df = over_df.fillna(df.mean())\n",
    "                X_over = over_df.iloc[:, :-1]\n",
    "                y_over = over_df.iloc[:, -1]                  \n",
    "                if k == 0:\n",
    "                    print(\"TRAIN_over(0/1/total):\", list(y_over).count(0), list(y_over).count(1), len(y_over)) \n",
    "                    print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))\n",
    "                model.fit(np.array(X_over).astype(float), np.array(y_over).astype(float))\n",
    "                result = model.predict(X_test)\n",
    "                result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "                acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "\n",
    "            res_df['S_{}_{}'.format(Strategy[j],ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                                                  np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                                                  np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                                                  np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                                                  acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "            \n",
    "    for h in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_{}\".format(Strategy[h]), \"==========\")         \n",
    "        for k in range(len(Model)):    \n",
    "            train_acc = []\n",
    "            train_pre = []\n",
    "            train_rec = []\n",
    "            train_spe = []\n",
    "            train_f1 = []\n",
    "            train_gmean = []\n",
    "            train_bacc = []\n",
    "            train_rauc = []            \n",
    "            list_acc = []\n",
    "            list_pre = []\n",
    "            list_rec = []\n",
    "            list_spe = []\n",
    "            list_f1 = []\n",
    "            list_gmean = []\n",
    "            list_bacc = []\n",
    "            list_rauc = []\n",
    "            \n",
    "            if min_strategy > Strategy[h]:\n",
    "                train_acc.append(0)\n",
    "                train_pre.append(0)\n",
    "                train_rec.append(0)\n",
    "                train_spe.append(0)\n",
    "                train_f1.append(0)\n",
    "                train_gmean.append(0)\n",
    "                train_bacc.append(0)\n",
    "                train_rauc.append(0)\n",
    "                list_acc.append(0)\n",
    "                list_pre.append(0)\n",
    "                list_rec.append(0)\n",
    "                list_spe.append(0)\n",
    "                list_f1.append(0)\n",
    "                list_gmean.append(0)\n",
    "                list_bacc.append(0)\n",
    "                list_rauc.append(0)\n",
    "                acc_t = 0\n",
    "                pre_t = 0\n",
    "                rec_t = 0\n",
    "                spe_t = 0\n",
    "                f1_t = 0\n",
    "                gmean_t = 0\n",
    "                bacc_t = 0\n",
    "                rauc_t = 0\n",
    "            \n",
    "            else:\n",
    "                # 5-fold-CV\n",
    "                n_iter=0\n",
    "                for train_index, val_index in skf.split(X, y):\n",
    "                    model = Model[k]\n",
    "                    n_iter += 1\n",
    "                    X_train = X.iloc[train_index]\n",
    "                    y_train= y.iloc[train_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                    # Loading Resmapled Data\n",
    "                    over_df = pd.read_csv('LLM_over/'\n",
    "                                          +str(i)+'_L_'+str(Strategy[h])+'_'+str(n_iter)+'th.csv')\n",
    "                    over_df = over_df.replace('False', False)  # sometimes False happen\n",
    "                    over_df = over_df.fillna(df.mean())   # sometime NAN happen\n",
    "                    X_train = over_df.iloc[:, :-1]\n",
    "                    y_train = over_df.iloc[:, -1]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN_over(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                    X_val = X.iloc[val_index]\n",
    "                    X_val = pd.concat([val_add.iloc[:,:-1], X_val], axis=0)\n",
    "                    y_val= y.iloc[val_index]\n",
    "                    y_val = pd.concat([val_add.iloc[:,-1], y_val], axis=0)\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                    # Array\n",
    "                    X_train = np.array(X_train)\n",
    "                    X_train = X_train.astype(float)\n",
    "                    y_train = np.array(y_train)\n",
    "                    y_train = y_train.astype(float)\n",
    "                    X_val = np.array(X_val)\n",
    "                    X_val = X_val.astype(float)\n",
    "                    y_val = np.array(y_val)\n",
    "                    y_val = y_val.astype(float)\n",
    "                    # Learning\n",
    "                    model.fit(X_train, y_train)  \n",
    "                    train_result = model.predict(X_train)\n",
    "                    train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                    train_acc.append(acc)\n",
    "                    train_pre.append(pre)\n",
    "                    train_rec.append(rec)\n",
    "                    train_spe.append(spe)\n",
    "                    train_f1.append(f1)\n",
    "                    train_gmean.append(gmean)\n",
    "                    train_bacc.append(bacc)\n",
    "                    train_rauc.append(rauc)    \n",
    "                    # Results \n",
    "                    result = model.predict(X_val)\n",
    "                    result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                    list_acc.append(acc)\n",
    "                    list_pre.append(pre)\n",
    "                    list_rec.append(rec)\n",
    "                    list_spe.append(spe)\n",
    "                    list_f1.append(f1)\n",
    "                    list_gmean.append(gmean)\n",
    "                    list_bacc.append(bacc)\n",
    "                    list_rauc.append(rauc)\n",
    "                            \n",
    "                # Test\n",
    "                model = Model[k]\n",
    "                # Loading Resmapled Data\n",
    "                over_df = pd.read_csv('LLM_over/'\n",
    "                                          +str(i)+'_L_'+str(Strategy[h])+'_'+str('comb')+'.csv')\n",
    "                over_df = over_df.replace('False', False)\n",
    "                over_df = over_df.fillna(df.mean())\n",
    "                X_over = over_df.iloc[:, :-1]\n",
    "                y_over = over_df.iloc[:, -1]                  \n",
    "                if k == 0:\n",
    "                    print(\"TRAIN_over(0/1/total):\", list(y_over).count(0), list(y_over).count(1), len(y_over)) \n",
    "                    print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))\n",
    "                model.fit(np.array(X_over).astype(float), np.array(y_over).astype(float))\n",
    "                result = model.predict(X_test)\n",
    "                result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "                acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "\n",
    "            res_df['L_{}_{}'.format(Strategy[h],ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                                                  np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                                                  np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                                                  np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                                                  acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t] \n",
    "            \n",
    "            \n",
    "    res_df.to_csv(\"veryimbalance_validation_test.csv\", mode = 'a', float_format='%.4g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3ed30",
   "metadata": {},
   "source": [
    "# 4. Very imbalanced with LLM+SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde0b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here, we get validation scores, not test scores.\n",
    "for i in very_imb_list:\n",
    "    df = pd.read_csv('data_newest/'+ str(i) +'.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    try:\n",
    "        minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    except:\n",
    "        minor = \"NONE\"    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    try:\n",
    "        print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "    except:\n",
    "        print('<Imabalance ratio>\\n',\"1: 0.00\")  \n",
    "        \n",
    "    # For validation & test (adding more data points removed from original dataset)\n",
    "    val_add = pd.read_csv('data_newest/'+str(i)+'_val.csv')\n",
    "    val_add.iloc[:,-1] = val_add.iloc[:,-1].replace(2, 1)\n",
    "    val_add.rename(columns={val_add.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    test_add = pd.read_csv('data_newest/'+str(i)+'_test.csv')\n",
    "    test_add.iloc[:,-1] = test_add.iloc[:,-1].replace(2, 1)\n",
    "    test_add.rename(columns={test_add.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]        # For validation\n",
    "    y = df_val.iloc[:, -1]         # For validation     \n",
    "    df_test = pd.concat([test_add, df_test], axis=0)\n",
    "    X_test = df_test.iloc[:, :-1]  # For test\n",
    "    y_test = df_test.iloc[:, -1]   # For test\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.astype(float)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = y_test.astype(float)\n",
    "    \n",
    "    res_df = pd.DataFrame({'Dataset':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, \n",
    "                       index = ['Acc_tr','Pre_tr','Rec_tr','Spe_tr','F1_tr','Gmean_tr','B_Acc_tr','R-AUC_tr',\n",
    "                                'Acc_val','Pre_val','Rec_val','Spe_val','F1_val','Gmean_val','B_Acc_val','R-AUC_val',\n",
    "                                'Acc_t','Pre_t','Rec_t','Spe_t','F1_t','Gmean_t','B_Acc_t','R-AUC_t'])\n",
    "    res_df.iloc[:,0] = [i for b in range(24)]\n",
    "    \n",
    "    ##################### For Loop for Every Loss Functions ####################### \n",
    "    try:\n",
    "        ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    except:\n",
    "        ind = 0\n",
    "    min_strategy = Strategy[ind]\n",
    "    adj_strategy = Strategy[ind+1]  # original min_strategy-> LLM oversmaple, so SMOTE is used from the next \n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        for k in range(len(Model)):  \n",
    "            train_acc = []\n",
    "            train_pre = []\n",
    "            train_rec = []\n",
    "            train_spe = []\n",
    "            train_f1 = []\n",
    "            train_gmean = []\n",
    "            train_bacc = []\n",
    "            train_rauc = []         \n",
    "            list_acc = []\n",
    "            list_pre = []\n",
    "            list_rec = []\n",
    "            list_spe = []\n",
    "            list_f1 = []\n",
    "            list_gmean = []\n",
    "            list_bacc = []\n",
    "            list_rauc = []\n",
    "                \n",
    "            if adj_strategy > Strategy[j]:\n",
    "                train_acc.append(0)\n",
    "                train_pre.append(0)\n",
    "                train_rec.append(0)\n",
    "                train_spe.append(0)\n",
    "                train_f1.append(0)\n",
    "                train_gmean.append(0)\n",
    "                train_bacc.append(0)\n",
    "                train_rauc.append(0)\n",
    "                list_acc.append(0)\n",
    "                list_pre.append(0)\n",
    "                list_rec.append(0)\n",
    "                list_spe.append(0)\n",
    "                list_f1.append(0)\n",
    "                list_gmean.append(0)\n",
    "                list_bacc.append(0)\n",
    "                list_rauc.append(0)\n",
    "                acc_t = 0\n",
    "                pre_t = 0\n",
    "                rec_t = 0\n",
    "                spe_t = 0\n",
    "                f1_t = 0\n",
    "                gmean_t = 0\n",
    "                bacc_t = 0\n",
    "                rauc_t = 0\n",
    "            \n",
    "            else:\n",
    "                # 5-fold-CV\n",
    "                n_iter=0\n",
    "                for train_index, val_index in skf.split(X, y):\n",
    "                    model = Model[k]\n",
    "                    n_iter += 1\n",
    "                    X_train = X.iloc[train_index]\n",
    "                    y_train= y.iloc[train_index]\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train))     \n",
    "                    # Loading Resmapled Data\n",
    "                    over_df = pd.read_csv(r'LLM_SMOTE/'\n",
    "                                          +str(i)+'_LS_'+str(Strategy[j])+'_'+str(n_iter)+'th.csv')\n",
    "                    over_df = over_df.replace('False', False)\n",
    "                    over_df = over_df.fillna(df.mean())\n",
    "                    X_train = over_df.iloc[:, :-1]\n",
    "                    y_train = over_df.iloc[:, -1]     \n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"TRAIN_over(0/1/total):\", list(y_train).count(0), list(y_train).count(1), len(y_train)) \n",
    "                    X_val = X.iloc[val_index]\n",
    "                    X_val = pd.concat([val_add.iloc[:,:-1], X_val], axis=0)\n",
    "                    y_val= y.iloc[val_index]\n",
    "                    y_val = pd.concat([val_add.iloc[:,-1], y_val], axis=0)\n",
    "                    if k == 0 and n_iter == 1:\n",
    "                        print(\"VALIDATION(0/1/total):\", list(y_val).count(0), list(y_val).count(1), len(y_val))\n",
    "                    # Array\n",
    "                    X_train = np.array(X_train)\n",
    "                    X_train = X_train.astype(float)\n",
    "                    y_train = np.array(y_train)\n",
    "                    y_train = y_train.astype(float)\n",
    "                    X_val = np.array(X_val)\n",
    "                    X_val = X_val.astype(float)\n",
    "                    y_val = np.array(y_val)\n",
    "                    y_val = y_val.astype(float)\n",
    "                    # Learning\n",
    "                    model.fit(X_train, y_train)\n",
    "                    train_result = model.predict(X_train)\n",
    "                    train_result_prob = model.predict_proba(X_train)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_train, train_result, train_result_prob)\n",
    "                    train_acc.append(acc)\n",
    "                    train_pre.append(pre)\n",
    "                    train_rec.append(rec)\n",
    "                    train_spe.append(spe)\n",
    "                    train_f1.append(f1)\n",
    "                    train_gmean.append(gmean)\n",
    "                    train_bacc.append(bacc)\n",
    "                    train_rauc.append(rauc)\n",
    "                    # Results \n",
    "                    result = model.predict(X_val)\n",
    "                    result_prob = model.predict_proba(X_val)[:, 1] # Get probability of class 1\n",
    "                    acc, pre, rec, spe, f1, gmean, bacc, rauc = get_results(y_val, result, result_prob)\n",
    "                    list_acc.append(acc)\n",
    "                    list_pre.append(pre)\n",
    "                    list_rec.append(rec)\n",
    "                    list_spe.append(spe)\n",
    "                    list_f1.append(f1)\n",
    "                    list_gmean.append(gmean)\n",
    "                    list_bacc.append(bacc)\n",
    "                    list_rauc.append(rauc)\n",
    "                            \n",
    "                # Test\n",
    "                model = Model[k]\n",
    "                # Loading Resmapled Data\n",
    "                over_df = pd.read_csv(r'LLM_SMOTE/'\n",
    "                                          +str(i)+'_LS_'+str(Strategy[j])+'_'+str('comb')+'.csv')\n",
    "                over_df = over_df.replace('False', False)\n",
    "                over_df = over_df.fillna(df.mean())\n",
    "                X_over = over_df.iloc[:, :-1]\n",
    "                y_over = over_df.iloc[:, -1]                  \n",
    "                if k == 0:\n",
    "                    print(\"TRAIN_over(0/1/total):\", list(y_over).count(0), list(y_over).count(1), len(y_over)) \n",
    "                    print(\"TEST(0/1/total):\", list(y_test).count(0), list(y_test).count(1), len(y_test))\n",
    "                model.fit(np.array(X_over).astype(float), np.array(y_over).astype(float))\n",
    "                result = model.predict(X_test)\n",
    "                result_prob = model.predict_proba(X_test)[:, 1] # Get probability of class 1\n",
    "                acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t = get_results(y_test, result, result_prob)\n",
    "\n",
    "            res_df['LS_{}_{}'.format(Strategy[j],ModelName[k])] = [np.mean(train_acc),np.mean(train_pre), np.mean(train_rec), np.mean(train_spe),\n",
    "                                                                   np.mean(train_f1), np.mean(train_gmean), np.mean(train_bacc), np.mean(train_rauc),\n",
    "                                                                   np.mean(list_acc),np.mean(list_pre), np.mean(list_rec), np.mean(list_spe),\n",
    "                                                                   np.mean(list_f1), np.mean(list_gmean), np.mean(list_bacc), np.mean(list_rauc),\n",
    "                                                                   acc_t, pre_t, rec_t, spe_t, f1_t, gmean_t, bacc_t, rauc_t]\n",
    "            \n",
    "    res_df.to_csv(\"veryimbalance_validation_test_LS.csv\", mode = 'a', float_format='%.4g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef234418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1e328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
