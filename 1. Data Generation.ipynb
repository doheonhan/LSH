{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234363ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datagen.oversampler import oversample   # LLM oversample\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)   # 5-fold-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [18, 41, 14, 43, 53, 28, 20, 63, 69, 56, 19, 25, 6, 24, 80, 32, 22, 15, 27, 33, 58,\n",
    "              46, 29, 64, 62, 17, 47, 13, 44, 9, 49, 55, 3, 35, 67, 54, 12, 7, 39, 36, 4, 79, 59, 52, 5, 57,\n",
    "              21, 50, 45, 42, 11, 1, 51, 38, 34, 16, 10, 2, 26, 91]\n",
    "print(len(final_list), final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f41975",
   "metadata": {},
   "source": [
    "# 1.SMOTE-5CV (48% x 5 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e5d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Generation \n",
    "for i in final_list:\n",
    "    df = pd.read_csv('ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .3f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]\n",
    "    y = df_val.iloc[:, -1]\n",
    "    \n",
    "    ##################### For Validation Set #######################\n",
    "    Strategy = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]\n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        over = SMOTE(sampling_strategy=Strategy[j], random_state=0)\n",
    "        if min_strategy > Strategy[j]:\n",
    "            continue         \n",
    "        else:     \n",
    "            n_iter=0\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                n_iter += 1\n",
    "                print(\"=======\", \"{}th-cv\".format(n_iter), \"=======\")\n",
    "                X_train = X.iloc[train_index]\n",
    "                y_train= y.iloc[train_index]\n",
    "                if n_iter == 1:\n",
    "                    print(list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                df_train = pd.concat([X_train, y_train], axis=1)\n",
    "                minority_data = df_train[df_train[\"NEW_LABEL\"] == 1]\n",
    "                print(\"Nedeed Samples:\",int((len(df_train)-len(minority_data))*Strategy[j]-len(minority_data)))\n",
    "                # Resmapling\n",
    "                X_train, y_train = over.fit_resample(X_train, y_train) \n",
    "                if n_iter == 1:\n",
    "                    print(list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                over_df = pd.concat([X_train, y_train], axis=1)\n",
    "                over_df.to_csv(\"SMOTE_over/ds{}_S_{}_{}th.csv\".format(i, Strategy[j], n_iter), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898afae",
   "metadata": {},
   "source": [
    "# 2.SMOTE-Train (70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db7fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Generation \n",
    "for i in final_list:\n",
    "    df = pd.read_csv('ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .3f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]\n",
    "    y = df_val.iloc[:, -1]\n",
    "    \n",
    "    ##################### For Validation Set #######################\n",
    "    Strategy = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]\n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        over = SMOTE(sampling_strategy=Strategy[j], random_state=0)\n",
    "        if min_strategy > Strategy[j]:\n",
    "            continue         \n",
    "        else:     \n",
    "            print(\"=======\", \"full-train\", \"=======\")\n",
    "            print(list(y).count(0), list(y).count(1), len(y))\n",
    "            minority_data = df_val[df_val[\"NEW_LABEL\"] == 1]\n",
    "            print(\"Nedeed Samples:\",int((len(df_val)-len(minority_data))*Strategy[j]-len(minority_data)))\n",
    "            # Resmapling\n",
    "            X_over, y_over = over.fit_resample(X, y) \n",
    "            print(list(y_over).count(0), list(y_over).count(1), len(y_over))\n",
    "            over_df = pd.concat([X_over, y_over], axis=1)\n",
    "            over_df.to_csv(\"SMOTE_over/ds{}_S_{}_full.csv\".format(i, Strategy[j]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb392b",
   "metadata": {},
   "source": [
    "# 3.LLM-5CV (48% x 5 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300f662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "for i in final_list:\n",
    "    df = pd.read_csv('ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]\n",
    "    y = df_val.iloc[:, -1]\n",
    "    \n",
    "    ##################### For Validation Set #######################\n",
    "    Strategy = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]\n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for h in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_{}\".format(Strategy[h]), \"==========\")       \n",
    "        if min_strategy > Strategy[h]:\n",
    "            continue\n",
    "        else:     \n",
    "            n_iter=0\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                n_iter += 1\n",
    "                print(\"=======\", \"{}th-cv\".format(n_iter), \"=======\")\n",
    "                X_train = X.iloc[train_index]\n",
    "                y_train= y.iloc[train_index]\n",
    "                if n_iter == 1:\n",
    "                    print(list(y_train).count(0), list(y_train).count(1), len(y_train))\n",
    "                # Resmapling\n",
    "                df_train = pd.concat([X_train, y_train], axis=1)\n",
    "                minority_data = df_train[df_train[\"NEW_LABEL\"] == 1]\n",
    "                print(\"Nedeed Samples:\",int((len(df_train)-len(minority_data))*Strategy[h]-len(minority_data)))\n",
    "                try:\n",
    "                    new_data = oversample(minority_data, \n",
    "                                          int((len(df_train)-len(minority_data))*Strategy[h]-len(minority_data)), # number of generated data samples\n",
    "                                          \"NEW_LABEL\",\n",
    "                                          1, # minor class\n",
    "                                          single_desc=True, single_vars=True\n",
    "                                          )\n",
    "                except:\n",
    "                    continue\n",
    "                over_df = pd.concat([df_train, new_data], axis=0)\n",
    "                over_df.to_csv(\"LLM_over/ds{}_L_{}_{}th.csv\".format(i, Strategy[h], n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5a005",
   "metadata": {},
   "source": [
    "# 4. LLM-Train (70%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaab8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "for i in final_list:\n",
    "    df = pd.read_csv('ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]\n",
    "    y = df_val.iloc[:, -1]\n",
    "    \n",
    "    ##################### For Validation Set #######################     \n",
    "    print(\"=======\", \"full-train\", \"=======\")\n",
    "    print(list(y).count(0), list(y).count(1), len(y))\n",
    "    minority_data = df_val[df_val[\"NEW_LABEL\"] == 1]\n",
    "    print(\"Nedeed Samples:\",int((len(df_val)-len(minority_data))*1-len(minority_data)))\n",
    "    # Resmapling\n",
    "    try:\n",
    "        new_data = oversample(minority_data, \n",
    "                              int((len(df_val)-len(minority_data))*1-len(minority_data)), # number of generated data samples\n",
    "                              \"NEW_LABEL\",\n",
    "                              1, # minor class\n",
    "                              single_desc=True, single_vars=True\n",
    "                              )\n",
    "    except:\n",
    "        continue\n",
    "    over_df = pd.concat([df_val, new_data], axis=0)\n",
    "    over_df.to_csv('LLM_over/ds{}_L_1.0_full.csv\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786cf82",
   "metadata": {},
   "source": [
    "# 5. LLM + SMOTE - CV (48% x 5 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b6993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Generation \n",
    "for i in final_list:\n",
    "    df = pd.read_csv('ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]\n",
    "    y = df_val.iloc[:, -1]\n",
    "    print(list(y).count(0), list(y).count(1), len(y))\n",
    "    print(list(y).count(0)*0.8, list(y).count(1)*0.8, len(y)*0.8)\n",
    "    ##################### For Validation Set #######################\n",
    "    Strategy = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]   \n",
    "    adj_strategy = Strategy[ind+1]  # original min_strategy-> LLM oversmaple, so SMOTE is used from the next \n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "        adj_strategy = Strategy[2]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        over = SMOTE(sampling_strategy=Strategy[j], random_state=0)\n",
    "        if adj_strategy > Strategy[j]:\n",
    "            continue\n",
    "        else:\n",
    "            for n_iter in range(1,6):\n",
    "                print(\"=======\", \"{}th-cv\".format(n_iter), \"=======\")\n",
    "                df_lm = pd.read_csv('LLM_over/'+'ds'+str(i)+'_L_'+str(min_strategy)+'_'+str(n_iter)+'th.csv')\n",
    "                print(str(i), str(min_strategy), str(n_iter))\n",
    "                df_lm = df_lm.replace('False', False)  # sometimes False happen\n",
    "                df_lm = df_lm.replace('FALSE', False)  # sometimes False happen\n",
    "                df_lm = df_lm.fillna(df.mean())   # sometime NAN happen\n",
    "                X_lm = df_lm.iloc[:, :-1]\n",
    "                y_lm = df_lm.iloc[:, -1]\n",
    "                if n_iter == 1:\n",
    "                    print(list(y_lm).count(0), list(y_lm).count(1), len(y_lm)) \n",
    "                minority_data = df_lm[df_lm[\"NEW_LABEL\"] == 1]\n",
    "                print(len(df_lm), len(minority_data), Strategy[j])\n",
    "                print(\"Nedeed Samples:\",int((len(df_lm)-len(minority_data))*Strategy[j]-len(minority_data)))\n",
    "                # Resmapling\n",
    "                X_lm, y_lm = over.fit_resample(X_lm, y_lm)\n",
    "                if n_iter == 1:\n",
    "                    print(list(y_lm).count(0), list(y_lm).count(1), len(y_lm))\n",
    "                over_df = pd.concat([X_lm, y_lm], axis=1)\n",
    "                over_df.to_csv(\"LLM_SMOTE/ds{}_LS_{}_{}th.csv\".format(i, Strategy[j], n_iter), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5805ca",
   "metadata": {},
   "source": [
    "# 6. LLM + SMOTE - Train (70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation \n",
    "for i in final_list:\n",
    "    df = pd.read_csv('ds'+ str(i) +'_new.csv')\n",
    "    print('+'*35, '{}th Dataset'.format(i), '+'*35)\n",
    "    \n",
    "    # Make major class as '0' and minor class as '1'\n",
    "    MAJOR = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() == max(df.iloc[:,-1].value_counts())].index[0] # Moj Label\n",
    "    minor = df.iloc[:,-1].value_counts()[df.iloc[:,-1].value_counts() != max(df.iloc[:,-1].value_counts())].index[0] # min Label    \n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(MAJOR, -100)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(minor, 1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(-100, 0)\n",
    "    df.rename(columns={df.columns[-1]:'NEW_LABEL'}, inplace=True)\n",
    "    print('<Modified Class>\\n', df.iloc[:,-1].value_counts())\n",
    "    print('<Imabalance ratio>\\n', \"1:{: .2f}\".format(df.iloc[:,-1].value_counts()[1]/df.iloc[:,-1].value_counts()[0]))\n",
    "        \n",
    "    ##################### Validation:Test = 70:30 #######################\n",
    "    df_val, df_test = train_test_split(df, test_size=0.3, random_state=100, stratify=df.iloc[:,-1])\n",
    "    X = df_val.iloc[:, :-1]\n",
    "    y = df_val.iloc[:, -1]\n",
    "\n",
    "    ##################### For Validation Set #######################\n",
    "    Strategy = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    ind = int((y.value_counts()[1]/y.value_counts()[0])//0.2)\n",
    "    min_strategy = Strategy[ind]   \n",
    "    adj_strategy = Strategy[ind+1]  # original min_strategy-> LLM oversmaple, so SMOTE is used from the next \n",
    "    if i == 33:\n",
    "        min_strategy = Strategy[1]\n",
    "        adj_strategy = Strategy[2]\n",
    "    print(\"<min_strategy>:\",min_strategy)   \n",
    "    \n",
    "    for j in range(len(Strategy)):\n",
    "        print(\"==========\", \"LLM_SMOTE_{}\".format(Strategy[j]), \"==========\") \n",
    "        over = SMOTE(sampling_strategy=Strategy[j], random_state=0)\n",
    "        if adj_strategy > Strategy[j]:\n",
    "            continue\n",
    "        else:\n",
    "            print(\"=======\", \"full-train\", \"=======\")\n",
    "            print(list(y).count(0), list(y).count(1), len(y))\n",
    "            df_lm = pd.read_csv('LLM_over/'+'ds'+str(i)+'_L_'+str(min_strategy)+'_'+str('comb')+'.csv')\n",
    "            print(str(i), str(min_strategy), str(n_iter))\n",
    "            df_lm = df_lm.replace('False', False)  # sometimes False happen\n",
    "            df_lm = df_lm.replace('FALSE', False)  # sometimes False happen\n",
    "            df_lm = df_lm.fillna(df.mean())   # sometime NAN happen\n",
    "            X_lm = df_lm.iloc[:, :-1]\n",
    "            y_lm = df_lm.iloc[:, -1] \n",
    "            minority_data = df_lm[df_lm[\"NEW_LABEL\"] == 1]\n",
    "            print(len(df_lm), len(minority_data), Strategy[j])\n",
    "            print(\"Nedeed Samples:\",int((len(df_lm)-len(minority_data))*Strategy[j]-len(minority_data)))\n",
    "            X_over, y_over = over.fit_resample(X_lm, y_lm)\n",
    "            print(list(y_over).count(0), list(y_over).count(1), len(y_over))\n",
    "            over_df = pd.concat([X_over, y_over], axis=1)\n",
    "            over_df.to_csv(\"LLM_SMOTE/ds{}_LS_{}_comb.csv\".format(i, Strategy[j]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aff2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90ab7146",
   "metadata": {},
   "source": [
    "# 7. Very Imbalanced Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaeca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_newest/ds8_new.csv')  # ds58, ds14, ds44\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30585004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We intentionally make it imbalanced.\n",
    "df_0 = df[df.iloc[:,-1]==1]\n",
    "df_1 = df[df.iloc[:,-1]==2]\n",
    "print(len(df_0), len(df_1), len(df_1)/len(df_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_imb_list = ['ds8_new_05', 'ds8_new_01', 'ds8_new_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11751274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.05)  # 1:0.05\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_05 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_05.iloc[:,-1].value_counts())\n",
    "df_05.to_csv('data_newest/ds8_new_05.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds8_new_05_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds8_new_05_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.01)  # 1:0.01\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_01 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_01.iloc[:,-1].value_counts())\n",
    "df_01.to_csv('data_newest/ds8_new_01.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds8_new_01_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds8_new_01_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.00)  # 1:0.00\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_00 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_00.iloc[:,-1].value_counts())\n",
    "df_00.to_csv('data_newest/ds8_new_00.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds8_new_00_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds8_new_00_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e59baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## data58 ##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11cc4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_newest/ds58_new.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We intentionally make it imbalanced.\n",
    "df_0 = df[df.iloc[:,-1]==1]\n",
    "df_1 = df[df.iloc[:,-1]==2]\n",
    "print(len(df_0), len(df_1), len(df_1)/len(df_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace121bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_imb_list = ['ds58_new_05', 'ds58_new_01', 'ds58_new_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c49c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.05)  # 1:0.05\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_05 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_05.iloc[:,-1].value_counts())\n",
    "df_05.to_csv('data_newest/ds58_new_05.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds58_new_05_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds58_new_05_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0965c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.01)  # 1:0.01\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_01 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_01.iloc[:,-1].value_counts())\n",
    "df_01.to_csv('data_newest/ds58_new_01.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds58_new_01_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds58_new_01_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.00)  # 1:0.00\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_00 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_00.iloc[:,-1].value_counts())\n",
    "df_00.to_csv('data_newest/ds58_new_00.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds58_new_00_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds58_new_00_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4c5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## data14 ##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_newest/ds14_new.csv')\n",
    "df = df.iloc[:,1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We intentionally make it imbalanced.\n",
    "df_0 = df[df.iloc[:,-1]==1]\n",
    "df_1 = df[df.iloc[:,-1]==2]\n",
    "print(len(df_0), len(df_1), len(df_1)/len(df_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_imb_list = ['ds14_new_05', 'ds14_new_01', 'ds14_new_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.05)  # 1:0.05\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_05 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_05.iloc[:,-1].value_counts())\n",
    "df_05.to_csv('data_newest/ds14_new_05.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds14_new_05_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds14_new_05_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a59c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.01)  # 1:0.01\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_01 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_01.iloc[:,-1].value_counts())\n",
    "df_01.to_csv('data_newest/ds14_new_01.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds14_new_01_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds14_new_01_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd54df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.00)  # 1:0.00\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_00 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_00.iloc[:,-1].value_counts())\n",
    "df_00.to_csv('data_newest/ds14_new_00.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds14_new_00_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds14_new_00_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ebdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## data44 ##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1927ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_newest/ds44_new.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f98049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We intentionally make it imbalanced.\n",
    "df_0 = df[df.iloc[:,-1]==1]\n",
    "df_1 = df[df.iloc[:,-1]==2]\n",
    "print(len(df_0), len(df_1), len(df_1)/len(df_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ad8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_imb_list = ['ds44_new_05', 'ds44_new_01', 'ds44_new_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.05)  # 1:0.05\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_05 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_05.iloc[:,-1].value_counts())\n",
    "df_05.to_csv('data_newest/ds44_new_05.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds44_new_05_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds44_new_05_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aacf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.01)  # 1:0.01\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_01 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_01.iloc[:,-1].value_counts())\n",
    "df_01.to_csv('data_newest/ds44_new_01.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds44_new_01_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds44_new_01_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = round(len(df_0)*0.00)  # 1:0.00\n",
    "df_1_samp = df_1.sample(n=N, random_state = 100)\n",
    "print(len(df_1_samp))\n",
    "df_00 = pd.concat([df_0, df_1_samp], axis=0)\n",
    "print(df_00.iloc[:,-1].value_counts())\n",
    "df_00.to_csv('data_newest/ds44_new_00.csv', index = False)\n",
    "\n",
    "# To add val(14%) & test(30%)\n",
    "samp_ind = df_1_samp.index\n",
    "df_1_va_te = df_1.drop(samp_ind)\n",
    "print(len(df_1_va_te))\n",
    "N_va = round(len(df_1_va_te)*(14/(14+30)))\n",
    "df_1_va = df_1_va_te.sample(n=N_va, random_state = 100)\n",
    "N_te = len(df_1_va_te)-N_va\n",
    "df_1_te = df_1_va_te.sample(n=N_te, random_state = 100)\n",
    "print(len(df_1_va), len(df_1_te))\n",
    "df_1_va.to_csv('data_newest/ds44_new_00_val.csv', index = False)\n",
    "df_1_te.to_csv('data_newest/ds44_new_00_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfc0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b18ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
